{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/header.png\" width=\"100%\">\n",
    "\n",
    "\n",
    "# Unit III: Probabilistic filtering\n",
    "#### Inferring user intention in a noisy world\n",
    "<b>[John Williamson](http://johnhw.com)</b> \n",
    "\n",
    "----\n",
    "\n",
    ">All theorems are true. \n",
    ">All models are wrong. \n",
    ">And all data are inaccurate. \n",
    ">\n",
    ">What are we to do? \n",
    "> We must be sure to remain uncertain.\n",
    ">\n",
    "> -- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"Capture.PNG\"/>\n",
    "*A probabilistic filter-based gesture recogniser*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "-----------------\n",
    "\n",
    "### What is probabilistic filtering?\n",
    "One view on interaction is to see user intentions as **unknown values** which are partially observed through input sensors. The time series of inputs only give a partial, noisy, incomplete view of intention. \n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">\n",
    "\n",
    "Probabilistic filtering makes it possible to track the evolution of some unknown variables [user intentions] given observed evidence [input], in a way that is **robust**. They work by inferring a **distribution** over possible hidden variables, and updating them over time.\n",
    "\n",
    "<img src=\"imgs/stochastic.png\" width=\"50%\">\n",
    "\n",
    "Probabilistic filtering is an **inverse probability** approach, and it requires that we think of interaction from a unique perspective. We have to explicitly be able to write down:\n",
    "\n",
    "* what we want to know (i.e. the **state space of intention**);\n",
    "* how that will change over time (i.e. the **dynamics of intention**);\n",
    "*  a model that *if we knew what the user intention was, what the expected behavior would be* (i.e. a **function mapping intention -> expected inputs**).\n",
    "\n",
    "Note that this last point is the **inverse** of the typical way of approaching this problem, where we try and find a mapping from a sensors to intention, by design or by learning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this computational HCI?\n",
    "Probabilistic filtering means writing down an **executable, statistical model** of behavior. This has the two key elements of computational interaction:\n",
    "* an explicit mathematical model of user-system behavior;\n",
    "* an algorithmic element that, using this model, can apply computational power to improving interaction.\n",
    "\n",
    "It satisfies the requirement that better interfaces can be achieved via \n",
    "* improved modeling;\n",
    "* more powerful algorithms;  \n",
    "* or increased computational power, \n",
    "\n",
    "rather than the workhorses of traditional HCI:\n",
    "* more design ingenuity;\n",
    "* and stronger evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are existing techniques?\n",
    "* **Crafted mappings**, where we try to find (by hand) transforms from sensors to intentions that are  simple or obvious. **Example:** a button, which has two physical states, and maps on to two intentional states via two electrical states. Pushed down = current flows = user intended to switch on. The mapping from electrical states to intentional states is **designed.**\n",
    "\n",
    "* **Machine learning**, where we train a system to recognize a class of input patterns as being representative of an intended behavior. **Example:** Finger gesture recognizer; hundreds of examples of many users performing one of N multi-touch gestures are recorded. These are used to train a random forest to classify the intended gesture. The mapping from electrical states (capacitive sensors) to intentional states is **learned**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits\n",
    "* **Robustness to noise** PFs work well even with sensors that are noisy.\n",
    "* **Robustness to poorly specified models** PFs can cope predictably even if our models are bad.\n",
    "* **Robustness to intermittence** PFs can continue sensibly interpolate when input cuts out.\n",
    "* **Uncertainty estimates** PFs **know how certain they are** and this can be used in the interaction design\n",
    "* **Better feedback** PFs predict distributions over past, present and future, and they offer the opportunity to give rich feedback insights to users.\n",
    "* **Flexible modeling** PFs can incorporate both fundamental modeling (e.g. physiological or cognitive models) and data-driven machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History\n",
    "* 1960s Kalman filter (Swerling, Kalman, Bucy), Extended Kalman Filter (Schmidt)\n",
    "* late 1960-1990s Particle filter / sequential Monte Carlo\n",
    "* 1992 Bootstrap filter (Gordon)\n",
    "* 1995 Unscented Kalman Filter (Uhlmann)\n",
    "* 1998 Condensation: particle filter for vision problems (Isard and Blake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principles [28 mins]\n",
    "### Overview diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case\n",
    "### Problem description\n",
    "We are going to solve xxx\n",
    "### Meat\n",
    "Meat goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key algorithm summary\n",
    "| Algorithm       | Dynamics       | State distribution | Efficiency | Optimizable |\n",
    "|-----------------|----------------|--------------------|------------|-----------|\n",
    "| Particle        | Arbitrary      | Arbitrary          | Low        | No        |\n",
    "| Kalman          | Linear         | Gaussian           | Very high  | Yes       |\n",
    "| Extended Kalman | Locally linear | Gaussian           | High       | Yes       |\n",
    "| Unscented Kalman| Arbitrary      | Gaussian           | High       | ?         |\n",
    "| HMM             | Transitions    | Discrete           | High       | Yes       |\n",
    "\n",
    "* Dynamics: permissible state transition functions.\n",
    "* State distribution: distribution type for representing current state.\n",
    "* Efficiency: computational efficiency.\n",
    "* Optimizable: can the parameters of the filter be automatically optimized given training data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gallery\n",
    "Research papers here (thumbnail + link), short description of why cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfalls\n",
    "Hands-on guru knowledge goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlook [5 mins]\n",
    "### Scope and limitations\n",
    "#### Limitations\n",
    "* PFs can be computationally intensive to run. \n",
    "* Curse-of-dimensionality can make the attractive simplicity of PFs work poorly in practice as the state space expands.\n",
    "* Particle filters are simple and elegant, but inferentially weak.\n",
    "* Kalman filters are rigid and restrictive, but very inferentially efficient.\n",
    "* Hybrid approaches (Ensemble Kalman filter, Unscented Kalman Filter, hybrid particle/Kalman filters) can trade these off, but aren't off the shelf solutions.\n",
    "\n",
    "\n",
    "### Resources\n",
    "How do I learn to do this in depth? Blogs, papers, software, videos, online courses, etc.\n",
    "* Read the [Condensation paper](http://vision.stanford.edu/teaching/cs231b_spring1415/papers/isard-blake-98.pdf).\n",
    "* Read [the Kalman filter in pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)\n",
    "* Watch [the particle filter without equations](https://www.youtube.com/watch?v=aUkBa1zMKv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future of probabilistic filtering\n",
    "\n",
    "#### Learned models\n",
    "\n",
    "Much use of probabilistic filters has depended on strong mathematical models of the fundamental process. For example, in rocket science, sophisticated physics models were used to specify the Kalman filters used for stable control. \n",
    "\n",
    "However, it is becoming increasingly possible to **infer** these models from observations. Techniques such as deep learning (for example variational autoencoders or generative adversarial networks) make it possible to learn very sophisticated *generative models* from observations of\n",
    "data. \n",
    "\n",
    "These models can be dropped into probabilistic filters to produce robust inferential engines for user interaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
