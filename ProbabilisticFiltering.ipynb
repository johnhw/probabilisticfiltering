{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/header.png\" width=\"100%\">\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit III: Probabilistic filtering\n",
    "#### Inferring user intention in a noisy world\n",
    "<b>[John Williamson](http://johnhw.com)</b> \n",
    "\n",
    "----\n",
    "\n",
    "    All theorems are true. \n",
    "    All models are wrong. \n",
    "    And all data are inaccurate. \n",
    "\n",
    "    What are we to do? \n",
    "    We must be sure to remain uncertain.\n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "-----------------\n",
    "### What are we going to do?\n",
    "We will:\n",
    "* show how to represent interaction problems as inference;\n",
    "* discuss how probabilistic filters can be used to attack these inference problems;\n",
    "* specifically show how motion-based interfaces can use probabilistic filtering to increase robustness.\n",
    "\n",
    "\n",
    "### What will we *practically* do?\n",
    "* We will build a 2D mouse gesture recognizer using a hybrid discrete/continuous particle filter. This will be a simple, robust classifier with rich feedback opportunities.\n",
    "\n",
    "<img  src=\"imgs/capture.png\" width=\"80%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### What is probabilistic filtering ?\n",
    "One view on interaction is to see user intentions as **unknown values** which are partially observed through input sensors. The time series of inputs from the user only give a partial, noisy, incomplete view of intention inside the user's head. \n",
    "\n",
    "Probabilistic filtering **(PF)** tracks the evolution of some unknown variables *[user intentions]* given observed evidence *[user input]*, in a way that is **robust**. Probabilistic filters infer a **distribution** over possible hidden (unobserved) variables, updating them over time. These filters are inherently **uncertain**, as they represent degrees of belief, and **dynamic**, as they explicitly model changing state over time.\n",
    "\n",
    "<img src=\"imgs/brain_inference.png\">\n",
    "\n",
    "#### Simulation viewpoint\n",
    "These filters are really *simulators*. They *simulate* how possible user behaviors might unfold over time. In some probabilistic filters, hundreds of parallel simulators are run, each with slightly different parameters. In all cases, the simulations are adjusted online to better match observed reality. The internal parameters that drive the simulation are the *unknown variables* we want to infer and the *evidence* is the observed reality that adjusts the simulation parameters.\n",
    "\n",
    "#### Properties\n",
    "Probabilistic filtering is:\n",
    "\n",
    "| Property | Why  |\n",
    "|----------|------|\n",
    "|**Bayesian**  |  Represents degrees of belief using probability distributions.    |\n",
    "|**predictive**  |  Works by comparing predictions with reality.   |\n",
    "|**generative** |  Involves generating (i.e. simulating) behavior.   |\n",
    "\n",
    "-----\n",
    "Probabilistic filtering is an **inverse probability** approach, and it requires that we think of interaction from an unique perspective. We have to explicitly be able to write down:\n",
    "\n",
    "* what we want to know (i.e. the **state space of intention**);\n",
    "* how that will change over time (i.e. the **dynamics of intention**);\n",
    "*  a model that *if we knew what the user intention was, what the expected behavior would be* (i.e. a **generative function mapping intention -> expected user inputs**).\n",
    "\n",
    "Note that this last point is the **inverse** of the typical way of approaching this problem, where we would try and find a mapping from a sensors to intention, by design or by learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this computational HCI?\n",
    "Probabilistic filtering means writing down an **executable, statistical model** of user behavior, then **running an inference algorithm** that updates beliefs based on the way observations evolve. The **parameters** of the filter can be **learned from user data**. The effectiveness of the filter can be quantitatively measured.\n",
    "\n",
    "This has key elements of computational interaction:\n",
    "* an explicit mathematical model of user-system behavior;\n",
    "* a way of updating that model with observed data from users;\n",
    "* an algorithmic element that, using this model, can apply computational power to improving interaction;\n",
    "* the ability to simulate or synthesize elements of the expected user-system behavior.\n",
    "* the ability to instrument the algorithm to quantitatively capture its performance.\n",
    "\n",
    "It satisfies the requirement that better interfaces can be achieved via:\n",
    "* improved modeling;\n",
    "* better data collection;\n",
    "* more powerful algorithms;  \n",
    "* or increased computational power, \n",
    "\n",
    "rather than the workhorses of traditional HCI:\n",
    "* more design ingenuity;\n",
    "* better elicitation;\n",
    "* and stronger evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are competitive approaches?\n",
    "#### **Crafted mappings**\n",
    "**where we try to find (by hand) transforms from sensors to intentions that are  simple or obvious.**\n",
    "\n",
    "**Example:** a button, which has two physical states, and maps on to two intentional states via two electrical states. Pushed down = current flows = user intended to switch on. The mapping from electrical states to intentional states is **designed.**\n",
    "<img src=\"imgs/undo.jpg\">\n",
    "*[Image credit: David Singleton via flickr.com CC-BY 2.0]*\n",
    "\n",
    "#### **Machine learned mappings**\n",
    "**where we train a system to recognize a class of input patterns as being representative of an intended behavior. **\n",
    "**Example:** Finger gesture recognizer; hundreds of examples of many users performing one of N multi-touch gestures are recorded. These are used to train a random forest to classify the intended gesture. The mapping from electrical states (capacitive sensors) to intentional states is **learned**.\n",
    "\n",
    "<img src=\"imgs/svm.jpg\" width=\"300px\">\n",
    "*[Image credit: Elisfm - via Wikimedia Commons; public domain]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits\n",
    "* **Robustness to noise** PFs work well even with input sensors that are noisy.\n",
    "* **Robustness to poorly specified models** PFs can cope predictably even if our models are bad.\n",
    "* **Robustness to intermittence** PFs can continue to sensibly interpolate when input cuts out.\n",
    "* **Uncertainty estimates** PFs *know how certain they are* and this can be used in the interaction design.\n",
    "* **Decoupled from real-time** PFs can infer past (smoothing), present (filtering) and future (forecasting).\n",
    "* **Inherent fusion of multiple input sensors** PFs are often used to solely to fuse together multiple inputs from different sensors.\n",
    "* **Better feedback** PFs  offer the opportunity to give users rich insight into the process of intention decoding.\n",
    "* **Flexible modeling** PFs can incorporate both fundamental modeling (e.g. physiological or cognitive models) and data-driven machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History\n",
    "* 1960s Kalman filter (Swerling, Kalman, Bucy), Extended Kalman Filter (Schmidt)\n",
    "* late 1960-1990s Particle filter / sequential Monte Carlo\n",
    "* 1992 Bootstrap filter (Gordon)\n",
    "* 1995 Unscented Kalman Filter (Uhlmann)\n",
    "* 1998 Condensation: particle filter for vision problems (Isard and Blake) \n",
    "\n",
    "**We will base our model in this unit roughly on the algorithm variant proposed by Isard and Blake.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principles \n",
    "-------\n",
    "\n",
    "> Interaction is the process of driving a system into a state compatible with user intentions.\n",
    "\n",
    "There are many perspectives on interaction from this stance, including:\n",
    "\n",
    "| Perspective   | Burden | Characteristic                         |\n",
    "|---------------|--------|----------------------------------------|\n",
    "| Communication | User   | User gets information into the system, by encoding intentions. |\n",
    "| Control       | Split  | User drives state towards intention via feedback control.   |\n",
    "| Inference     | System | System infers what user intention is from sensed user actions. |\n",
    "\n",
    "### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a hidden variable: what the user wants a system to do. \n",
    "* **Observations are noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous.\n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview diagram\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/control_loop.png\">\n",
    "\n",
    "\n",
    "\n",
    "Notation:\n",
    "* We have a sequence of states over time, indexed by $t$\n",
    "* $X_t$ the variable we want to know (at time $t$) (e.g. an intention inside a user's head). \n",
    "* $Y_t$ the variable we can observe (e.g. a sensor we can get readings from).\n",
    "* For computational simplicity, we assume **discrete time**, i.e. we observe sensors in a discrete, regularly sampled way.\n",
    "\n",
    "* We want to compute $P(X_t|Y_t)$ (the **inverse problem**). \n",
    "* We use a **forward model** $P(Y_t|X_t)$ to infer this.\n",
    "* We need to define two functions: ${\\bf\\hat{y_t}} = f({\\bf \\hat{x}}_t)$ (the **observation function**) and $\\hat{\\bf x}_{t} = g(\\hat{\\bf x}_{t-1})$ (the **dynamics** or **process function**).\n",
    "* We also need a **weighting function** $w(\\bf\\hat{y_t},{\\bf y_t})$ that computes how similar a simulated observation $\\bf\\hat{y_t}$ is to the real observation $\\bf y_t$. This is used to compute the likelihood $p(\\bf\\hat{y_t}|{\\bf y_t})$.\n",
    "\n",
    "* $f$, $g$ and $w$ are often very simple functions.\n",
    "\n",
    "<img src=\"imgs/stochastic.png\" width=\"75%\">\n",
    "\n",
    "#### Predictor-corrector\n",
    "**This is a predictor-corrector model**; the dynamics model supplies predictions, and corrections to those predictions are applied by the observation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Problem description\n",
    "We are going to solve a simple problem:\n",
    "\n",
    "* Recognising simple 2D gestures, drawn with a mouse.\n",
    "\n",
    "This is readily solved with \"standard\" (inverse) algorithms, but we will show how a model-led approach lets us encode our assumptions elegantly **and** we get all the benefits of *probabilistic* tracking. We'll see how probabilistic filters degrade gracefully when our models are bad or measurements are noisy.\n",
    "\n",
    "#### Algorithm\n",
    "We will use the **particle filter** algorithm (technically the **SIR** variant, which is the simplest to understand).\n",
    "\n",
    "A particle filter requires that we specify:\n",
    "* A **dynamics function** that predicts how we expect the world to evolve, which takes \n",
    "$\\hat{\\bf{x}}_t \\rightarrow \\hat{\\bf x}_{t+1}$\n",
    "* An **observation function** that predicts what we expect to observe, given a hypothesized state $\\hat{\\bf y}_t \\rightarrow \\hat{\\bf{x}_t}$\n",
    "* A **weight function**, that, given a hypothesized observation $\\hat{\\bf y}_t$, can be used to compute $p(\\hat{\\bf y}_t|{\\bf y}_t)$. This is performed by computing weights $w_i$ for each particle $i$ and then normalizing to produce a probability:\n",
    "$$p^{(i)}(\\hat{\\bf y}_t|{\\bf y}_t) = \\frac{w_i}{\\sum_j w_j}$$\n",
    "* A set of **prior distributions** that specify our initial guesses for $\\hat{\\bf x}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic filtering\n",
    "We will first implement a basic particle filter that can track a very simple one dimensional time series. \n",
    "\n",
    "Then, we will show how this can generalise to an interesting HCI problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the things we need\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pykalman, pfilter\n",
    "import ipywidgets\n",
    "import IPython\n",
    "import matplotlib, matplotlib.colors\n",
    "matplotlib.rcParams['figure.figsize'] = (14.0, 8.0)\n",
    "%matplotlib inline\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test data\n",
    "To test the particle filter, we will try and track a very simple, 1D sine wave:\n",
    "$$Y_t=\\sin(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.linspace(0,20,100).reshape(-1,1)\n",
    "x = np.sin(t)\n",
    "plt.plot(t,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple model\n",
    "We will use a very simple model\n",
    "\n",
    "* **Dynamics**\n",
    "We assume that there are no predictable dynamics, just some Gaussian noise $X_t = X_{t+1} + \\epsilon,\\  \\epsilon \\sim N(0,\\sigma_p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma_p = 0.2              # the process noise \n",
    "beta = 0.25                # the RBF width\n",
    "simulated_noise = -2     # the simulated noise we added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Identity Example\n",
    "def dynamics(x):\n",
    "    # tomorrow is the same as today\n",
    "    # but slightly randomly different\n",
    "    # we literally *add* noise to our previous state\n",
    "    return x+np.random.normal(0,sigma_p,x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show what this dynamics model looks like, if we had no resampling step in the filter. This makes predictions without ever having seen any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate_dynamics(priors, dynamics, steps, n_runs=1):\n",
    "    runs = []\n",
    "    def simulate_run():\n",
    "        x = np.array([p.rvs() for p in priors])\n",
    "        xs = [x]    \n",
    "        for i in range(steps):\n",
    "            x = dynamics(x)\n",
    "            xs.append(x)\n",
    "        return xs    \n",
    "    return np.array([simulate_run() for j in range(n_runs)])\n",
    "    \n",
    "simulated = simulate_dynamics(priors=[norm(0,1)], dynamics=dynamics, steps=200, n_runs=20)   \n",
    "plt.plot(simulated[:,:,0].T, alpha=0.3, c='C0');\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"X\")\n",
    "plt.title(\"Simulated runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Observation**\n",
    "We assume that the sensor we measure is the value we want to infer, i.e. $Y_t=X_t$, and $g(X_t)$  is just the identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def observe(x):\n",
    "    # we observe x directly\n",
    "    return x[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Weighting**\n",
    "We weight samples according to how similar they are to the observed output. We use a simple **heat kernel**:\n",
    "$$w_i = e^{\\left(-\\frac{(y-y^\\prime)^2}{2\\beta^2}\\right)}$$\n",
    "$\\beta$ is a parameter that lets us specify how precise our matching between observation and reality is.\n",
    "\n",
    "Note that this gives more weight to particles that are more similar to the observation: it is a **similarity** function, not a distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight(true_y, hypothesized_y):\n",
    "    # RBF similarity function    \n",
    "    return np.exp(-np.sum((true_y-hypothesized_y)**2, axis=0)/(0.5*beta**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what this function looks like, comparing a true value of 0 with values in [-1, 1], $\\beta=0.25$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypo = np.linspace(-1,1,100).reshape(1,100)\n",
    "plt.plot(hypo.reshape(100,), weight(0, hypo))\n",
    "plt.axvline(0,c='C1')\n",
    "plt.xlabel(\"Hypothesized value\")\n",
    "plt.ylabel(\"Unnormalised weight\")\n",
    "plt.title(\"RBF kernel, $\\\\beta$=0.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Priors**\n",
    "We assume a very simple prior on $X$; that it is normally distributed, mean 0, variance 1, $X_0 \\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we assume that, before seeing any evidence, that the particles are \n",
    "# normally distributed about 0, with std. dev. 1.0\n",
    "prior = [norm(0,1)] # x ~ N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Filter creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf_simple = pfilter.ParticleFilter(initial=prior, \n",
    "                                    observe_fn=observe,\n",
    "                                    n_particles=200,                                    \n",
    "                                    dynamics_fn=dynamics,\n",
    "                                    weight_fn=weight,                    \n",
    "                                    resample_proportion=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_pfilter(pfilter, inputs):\n",
    "    \"\"\"Apply a particle filter to a time series of inputs,\n",
    "    and return the particles, their weights, and the mean\n",
    "    estimated state\"\"\"    \n",
    "    # reset filter\n",
    "    pfilter.init_filter()\n",
    "    particles = []\n",
    "    weights = []\n",
    "    means = []    \n",
    "    # apply to each element of the time series\n",
    "    for i in range(len(inputs)):    \n",
    "        pfilter.update([inputs[i]])\n",
    "        particles.append(pfilter.particles)    \n",
    "        weights.append(pfilter.weights)\n",
    "        means.append(pfilter.mean_state)        \n",
    "    return np.array(particles), np.array(weights), np.array(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a utility function to plot the results of running a particle filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_pfilter(time,expected, observed, particles, weights, means):\n",
    "    \"\"\"Apply a particle filter to a time series, and plot the\n",
    "    first component of the predictions alongside the expected\n",
    "    output.\"\"\"\n",
    "    # expected output\n",
    "    plt.plot(time, expected, 'C1', lw=3)\n",
    "    plt.plot(time, observed, '+C3', lw=3)\n",
    "    \n",
    "    # particles \n",
    "    ts = np.tile(time[:,None], particles.shape[1]).ravel()\n",
    "    weights =  weights.ravel()    \n",
    "    rgba_colors = np.zeros((len(weights),4))\n",
    "    rgba_colors[:,0:3] = matplotlib.colors.to_rgb('C2')\n",
    "    weights *= 10\n",
    "    rgba_colors[:, 3] = np.clip(weights, 0, 1)\n",
    "    plt.scatter(ts, particles[:,:,0].ravel(),  c=rgba_colors, s=2)\n",
    "    # mean estimation\n",
    "    plt.plot(time, means, 'C0--', lw=2)\n",
    "    # legend\n",
    "    plt.legend([\"True\", \"Observed\", \"Mean estimate\", \"Particle\"])\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"X\")\n",
    "    plt.title(\"Particle filter estimate\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_filter(sig=0.1, bet=0.5, noise=-2):\n",
    "    global sigma_p, beta, noise_level\n",
    "    sigma_p = sig\n",
    "    beta = bet\n",
    "    noise_level = 10**noise\n",
    "    noise = np.random.normal(0,noise_level, x.shape)\n",
    "    plt.figure(figsize=(12,7))\n",
    "    y = x + noise\n",
    "    particles, weights, means = run_pfilter(pf_simple, y)\n",
    "    plot_pfilter(t, x, y, particles, weights, means)\n",
    "    plt.title(\"Sigma=%.2f, Beta=%.2f, Noise=%.2e\" % (sigma_p, beta, noise_level))\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    \n",
    "run_filter(sig=0.1, bet=0.5, noise=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's adjust these interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipywidgets.interact_manual(run_filter, sig=(0.0, 2, 0.05), bet=(0.1, 5.0, 0.1), noise = (-5.0, 1.0, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to note\n",
    "* This is a trivial model, but still tracks \"complex\" functions, because it is adapting to observations\n",
    "* Things to adjust:\n",
    "    * noise level\n",
    "    * rbf width beta\n",
    "    * dynamics noise sigma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more interesting example\n",
    "Imagine we wanted to infer the **phase** of the oscillator driving this sine wave. The phase variable is not observable, but we want to infer it from the observed oscillation. Furthermore, we want the *unwrapped* phase, i.e. we expect the phase to monotonically increase.\n",
    "\n",
    "We can encode these assumptions in our model, then see if the particle filter is able to infer the hidden parameter over time.\n",
    "\n",
    "* **Observation**\n",
    "We postulate an observation model:\n",
    "$$Y_t = \\sin(X_t)$$\n",
    "i.e. that what we see is the effect of sine on a hidden variable $X_t$.\n",
    "Because we defined $Y_t=\\sin(t)$, we are actually trying to infer $t$.\n",
    "\n",
    "* **Dynamics**\n",
    "We assume that we have a very simple dynamical system in discrete time, where we have a velocity and a position.\n",
    "$$X_t = \\begin{bmatrix}x \\\\ \\dot{x}\\end{bmatrix},$$ and \n",
    "$$X_{t+1} = X_t + \\begin{bmatrix}\\dot{x} \\\\ 0 \\end{bmatrix}.$$\n",
    "\n",
    "This means that if we start linearly increasing or decreasing at a certain rate, we should expect to keep doing so.\n",
    "\n",
    "* **Priors**\n",
    "We again assume that the initial distribution is normally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Example\n",
    "sigma_x = 0.1\n",
    "sigma_dx = 0.001\n",
    "\n",
    "def linear_dynamics(x):        \n",
    "    nx = np.dot(x,np.array([[1,0],\n",
    "                            [1,1]]))        \n",
    "    process_sigmas = [sigma_x, sigma_dx] # how much noise for x and dx    \n",
    "    nx += np.random.normal(0,process_sigmas,x.shape)\n",
    "    return nx\n",
    "\n",
    "def observe_sin(x):    \n",
    "    # y = sin(x)    \n",
    "    return np.sin(x[:,0])\n",
    "\n",
    "def weight_sin(true_y, hypothesized_y):    \n",
    "    return np.exp(-np.sum((true_y-hypothesized_y)**2, axis=0)/beta)\n",
    "    \n",
    "from scipy.stats import norm\n",
    "prior = [norm(0,1), norm(0,0.25)] \n",
    "\n",
    "pf_sin = pfilter.ParticleFilter(initial=prior, \n",
    "                                observe_fn=observe_sin,\n",
    "                                n_particles=200,\n",
    "                                dynamics_fn=linear_dynamics,\n",
    "                                weight_fn=weight_sin,                    \n",
    "                                resample_proportion=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_sinfilter(sig_x=0.1, sig_dx=0.01, bet=0.25, noise=-2):\n",
    "    global sigma_p, beta, noise_level\n",
    "    sigma_x = sig_x\n",
    "    sigma_dx = sig_dx\n",
    "    beta = bet\n",
    "    noise_level = 10**noise\n",
    "    noise = np.random.normal(0,noise_level, x.shape)\n",
    "    plt.figure(figsize=(12,7))\n",
    "    y = x + noise\n",
    "    particles, weights, means = run_pfilter(pf_sin, y)\n",
    "    plot_pfilter(t, t, y, particles, weights, means)\n",
    "    plt.title(\"Sigma_x=%.2f, Sigma_dx=%.2f, Beta=%.2f, Noise=%.2e\" % (sigma_x, sigma_dx, beta, noise_level))\n",
    "    \n",
    "ipywidgets.interact_manual(run_sinfilter, sig_x=(0.0, 2, 0.05), sig_dx=(0.0, 0.5, 0.01), \n",
    "                           bet=(0.1, 5.0, 0.1), noise = (-5.0, 1.0, 0.1))    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to note\n",
    "* The particle filter was able to infer the hidden state, despite only having a forward model (i.e knowledge of $\\sin(x)$, **not** $\\sin^{-1}(x)$)\n",
    "* It correctly unwrapped phase, because we primed it with the dynamics model to expect values that would increase at a linear rate.\n",
    "* This problem results in *multimodal* distributions, because there are an infinite number of solutions to $y=sin(x)$ because we can add any multiple of $2\\pi$ without changing anything.\n",
    "We can see these as fainter lines on the particle plot.\n",
    "* This means that the particle mean is not actually a good estimate in this case! A better choice might be the most likely particle -- the Maximum A Posteriori (MAP) estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Gesture recognition\n",
    "We will base our algorithm directly on the one given in [A Probabilistic Framework for Matching\n",
    "Temporal Trajectories](http://www.cs.toronto.edu/~jepson/papers/BlackJepsonECCV1998.pdf).\n",
    "### Problem\n",
    "We want to recognise 2D gestures drawn with a mouse (or stylus). \n",
    "* We *observe* sequences of $x,y$ coordinates over time.\n",
    "* We have some example templates for particular shapes that we want to match (e.g. letters)\n",
    "* We don't know:\n",
    "    * where the user will start drawing a gesture\n",
    "    * how big the gesture will be\n",
    "    * whether it will be rotated or distorted\n",
    "    * how fast the user will draw the gesture (it may well be drawn at a non-constant speed)\n",
    "* We want to be able to identify:    \n",
    "\n",
    "\n",
    "\n",
    "### Parameters\n",
    "<img src=\"imgs/gesture.png\">\n",
    "We have one of $n$ possible gestures\n",
    "* $i$ the number of the gesture\n",
    "\n",
    "Our model says a gesture will be identical to the template for that class of gesture, but might vary in:\n",
    "* $s$ overall scale, within some tolerance\n",
    "* $x,y$ centre position (could be anywhere on screen)\n",
    "* $\\theta$ small changes in rotation (e.g. $<45^o$)\n",
    "\n",
    "We must take note that what we observe is a position at a **single time point** in a gesture. This means we must estimate how far through a gesture we are.\n",
    "* $\\phi$ the proportion of gesture complete, in the fraction [0,1].\n",
    "* $\\dot{\\phi}$ the rate at which the gesture is being performed (i.e. fast or slow).\n",
    "\n",
    "### Model\n",
    "We can write down a very simple model:\n",
    "\n",
    "#### Observation\n",
    "\n",
    "* Given a gesture $i$, we have a template $G_i(\\phi)$, which is returns an point for any value of $\\phi$.\n",
    "* We expect to observe $AG_i(\\phi)$, where $A$ is a transformation matrix applying the translation $x,y$, the scaling $s$ and the rotation $\\theta$.\n",
    "\n",
    "#### Priors\n",
    "* $s_0$ $N(1,0.5)$, should be around original size, with some latitude\n",
    "* $x_0,y_0$ $U(0,\\text{max_screen_size})$, could be anywhere on screen\n",
    "* $\\theta_0$ $N(0,15)$, angle will be close to original, with std. dev. of ~15 degrees\n",
    "* $\\phi_0$ $N(0,0.1)$, gestures will begin close to their start\n",
    "* $\\dot{\\phi}_0$ N($\\mu_{\\dot{\\phi}}, \\sigma_{\\dot{\\phi}})$), gesture speeds will be distributed according to the observed speeds from the template\n",
    "* $i_0$ discrete $U(0,n-1)$, could be any gesture\n",
    "\n",
    "#### Dynamics\n",
    "* $s_{t+1} = s_{t} + \\epsilon_s$ scale can drift slowly\n",
    "* $x_{t+1} = x_{t} + \\epsilon_x$ position can drift slowly\n",
    "* $y_{t+1} = y_{t} + \\epsilon_y$  \n",
    "* $\\theta_{t+1} = \\theta_{t} + \\epsilon_\\theta$ orientation can drift slowly\n",
    "* $i_{t+1}=i_{t}$  gesture class never changes\n",
    "* $\\phi_{t+1} = \\phi_{t} + \\dot{\\phi}_{t} + \\epsilon_y$ progress is steady, with some drift\n",
    "* $\\dot{\\phi}_{t+1} = \\dot{\\phi}_{t} + \\epsilon_y$ progress rate can drift\n",
    "\n",
    "### Code\n",
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key algorithm summary\n",
    "There are many probabilistic filtering algorithms. The particle filter is easy to understand and the most general, but it can be inefficient (it can take many particles to estimate state reliably). Particle filters are the only widely-used class of algorithm which can natively support both discrete and continuous parameters.\n",
    "\n",
    "Alternatives, like the Kalman filter, can estimate with much less computation, but are inflexible in terms of the distributions they can represent, and the dynamics of the models they can cope with. \n",
    "\n",
    "There are many variants of the Kalman filter which extend it in various ways; of these the *unscented Kalman filter (UKF)* is one of the most general and applicable. The UKF can cope with arbitrary continuous dynamics, which makes it suitable for many problems where there are nonlinearities.\n",
    "\n",
    "| Algorithm       | Dynamics       | State distribution | Efficiency | Optimizable |\n",
    "|-----------------|----------------|--------------------|------------|-----------|\n",
    "| Particle        | Arbitrary      | Arbitrary          | Low        | Tricky    |\n",
    "| Kalman          | Linear         | Gaussian           | Very high  | Easy      |\n",
    "| Extended Kalman | Locally linear | Gaussian           | High       | Yes       |\n",
    "| Unscented Kalman| Arbitrary      | Gaussian           | High       | Tricky    |\n",
    "| HMM             | Transitions    | Discrete           | High       | Yes       |\n",
    "\n",
    "* Dynamics: permissible state transition functions (i.e. how we go from now to the next timestep).\n",
    "* State distribution: distribution type for representing current state. Gaussian distributions are very efficient, but can't represent multiple modes.\n",
    "* Efficiency: computational efficiency.\n",
    "* Optimizable: is there an algorithm to optimize the  parameters of the filter be *automatically* given training data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gallery\n",
    "Research papers here (thumbnail + link), short description of why cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfalls\n",
    "Hands-on guru knowledge goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "---------------------\n",
    "### Scope and limitations\n",
    "#### Scope\n",
    "\n",
    "#### Limitations\n",
    "* PFs can be computationally intensive to run. \n",
    "* Curse-of-dimensionality can make the attractive simplicity of PFs work poorly in practice as the state space expands.\n",
    "* Sometimes the inverse probability model can be hard to formulate.\n",
    "* Particle filters are simple and elegant, but inferentially weak.\n",
    "* Kalman filters are rigid and restrictive, but very inferentially efficient.\n",
    "* Hybrid approaches (Ensemble Kalman filter, Unscented Kalman Filter, hybrid particle/Kalman filters, Rao-Blackwellized filters) can trade these qualities off, but they aren't off the shelf solutions (i.e. you need an expert!).\n",
    "\n",
    "\n",
    "### Resources\n",
    "#### Basic\n",
    "* Read the [Condensation paper](http://vision.stanford.edu/teaching/cs231b_spring1415/papers/isard-blake-98.pdf).\n",
    "* Read [the Kalman filter in pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)\n",
    "* Watch [the particle filter without equations](https://www.youtube.com/watch?v=aUkBa1zMKv4)\n",
    "\n",
    "#### Advanced\n",
    "* [A technical but succinct and clear explanation of the particle filter](http://www.cns.nyu.edu/~eorhan/notes/particle-filtering.pdf)\n",
    "* [A bibliography of particle filter papers](http://www.stats.ox.ac.uk/~doucet/smc_resources.html)\n",
    "\n",
    "#### Probabilistic filters in HCI\n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Future of probabilistic filtering\n",
    "\n",
    "#### Learned models\n",
    "\n",
    "Much use of probabilistic filters has depended on strong mathematical models of the fundamental process. For example, in rocket science, sophisticated physics models were used to specify the Kalman filters used for stable control. \n",
    "\n",
    "However, it is becoming increasingly possible to **infer** these models from observations. Techniques such as deep learning (for example variational autoencoders or generative adversarial networks) make it possible to learn very sophisticated *generative models* from observations of\n",
    "data.  These models can be dropped into probabilistic filters to produce robust inferential engines for user interaction.\n",
    "\n",
    "##### Example\n",
    "As an illustrative example, we recently built a touch pose estimator. We trained DCNN to predict finger pose from sensor images (inverse model), a separate deconvolutional CNN to predict sensor images from finger poses (forward model) and then fused these using a particle filter.\n",
    "\n",
    "<img src=\"imgs/fwd_inv.png\">\n",
    "This combined gives substantial robustness, and we were able to introduce a simple dynamics model, which filters out completely implausible movements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
